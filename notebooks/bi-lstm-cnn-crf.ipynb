{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **<span style=\"color:#344ceb;\"> Library Installations</span>**","metadata":{}},{"cell_type":"code","source":"!pip install keras_preprocessing\n!pip install tensorflow-addons\n!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:03:35.087843Z","iopub.execute_input":"2023-05-25T09:03:35.088281Z","iopub.status.idle":"2023-05-25T09:04:19.668008Z","shell.execute_reply.started":"2023-05-25T09:03:35.088246Z","shell.execute_reply":"2023-05-25T09:04:19.666837Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting keras_preprocessing\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras_preprocessing) (1.23.5)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from keras_preprocessing) (1.16.0)\nInstalling collected packages: keras_preprocessing\nSuccessfully installed keras_preprocessing-1.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.10/site-packages (0.20.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (21.3)\nRequirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (2.13.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-addons) (3.0.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.23.5)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=176b96e734aa79b1046f6da0d693c0dcb9d86d636ebea5b993ecaf741fbaa69d\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# **<span style=\"color:#344ceb;\">Library Import</span>**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom time import sleep\nfrom tqdm import tqdm\nimport keras\nimport tensorflow as tf\nfrom keras.layers import Input\nfrom keras.layers import Embedding\nfrom keras.layers import Bidirectional\nfrom keras.layers import LSTM\nfrom keras import regularizers\nfrom keras.layers import TimeDistributed\nfrom keras.layers import Dropout\nfrom keras.layers import Dense\nfrom keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.initializers import RandomUniform\nfrom keras import regularizers\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv1D\nfrom keras.layers import Flatten\nfrom keras.layers import concatenate\nfrom keras.layers import MaxPooling1D\nfrom keras.layers import InputLayer\nfrom tensorflow_addons.layers import CRF\nfrom tensorflow.keras.layers import SpatialDropout1D\nfrom tensorflow_addons.text.crf_wrapper import CRFModelWrapper\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:04:19.671095Z","iopub.execute_input":"2023-05-25T09:04:19.671535Z","iopub.status.idle":"2023-05-25T09:04:36.094113Z","shell.execute_reply.started":"2023-05-25T09:04:19.671496Z","shell.execute_reply":"2023-05-25T09:04:36.093015Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/voc-processed-data/train-nl.tsv\", sep=\"\\t\")\ntest = pd.read_csv(\"/kaggle/input/voc-processed-data/test-nl.tsv\", sep=\"\\t\")\ndev = pd.read_csv(\"/kaggle/input/voc-processed-data/dev-nl.tsv\", sep=\"\\t\")\n\ndata = pd.concat([train, test, dev], ignore_index=True)\nprint(len(data))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:04:36.095720Z","iopub.execute_input":"2023-05-25T09:04:36.096624Z","iopub.status.idle":"2023-05-25T09:04:36.827165Z","shell.execute_reply.started":"2023-05-25T09:04:36.096568Z","shell.execute_reply":"2023-05-25T09:04:36.826183Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"506867\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_data(data):\n    data['Sentence'] = data['TOKEN'].str.extract(r'# document_path = (.*)', expand=False).ffill()\n    data = data.dropna()\n\n    # create a dictionary to map unique strings to Sentence numbers\n    sentence_dict = {}\n    count = 1\n    for sentence in data['Sentence'].unique():\n        sentence_dict[sentence] = count\n        count += 1\n\n    # map the 'Sentence #' column with the dictionary\n    data['Sentence'] = data['Sentence'].map(sentence_dict)\n    data = data.reset_index(drop=True)\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:04:36.829580Z","iopub.execute_input":"2023-05-25T09:04:36.830238Z","iopub.status.idle":"2023-05-25T09:04:36.837389Z","shell.execute_reply.started":"2023-05-25T09:04:36.830200Z","shell.execute_reply":"2023-05-25T09:04:36.836524Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = preprocess_data(data)\ndf = df[['Sentence', 'TOKEN', 'NE-MAIN']]\n\ndf.rename(columns={\"TOKEN\": \"Word\",\"NE-MAIN\":\"Tag\"},inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:04:36.840083Z","iopub.execute_input":"2023-05-25T09:04:36.840431Z","iopub.status.idle":"2023-05-25T09:04:38.964038Z","shell.execute_reply.started":"2023-05-25T09:04:36.840400Z","shell.execute_reply":"2023-05-25T09:04:38.962978Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_310/4232299772.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data['Sentence'] = data['Sentence'].map(sentence_dict)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Sentence       Word Tag\n0         1      heste   O\n1         1  afschrift   O\n2         1          m   O\n3         1         In   O\n4         1        den   O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Word</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>heste</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>afschrift</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>m</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>In</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>den</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom keras_preprocessing.sequence import pad_sequences\n\n\nclass ContextNER:\n\n    __X, __y = None, None\n    X_array, y_array = None, None\n\n    word2idx, idx2word = None, None\n    tag2idx, idx2tag = None, None\n    y_array_normal = None\n\n    def __init__(self, df, all_words, max_len=None):\n\n        self.__df = df\n\n        self.all_words = set(all_words)\n        self.all_tags = set(df.Tag.values)\n\n        self.sentences = self.__build_sentences()\n\n        self.num_words = len(self.all_words) + 2\n        self.num_tags = len(self.all_tags) + 1\n\n        if max_len:\n            self.max_len = max_len\n        else:\n            self.max_len = self._get_maxlen()\n\n        self.__build_Xy()\n        self.__build_parsers()\n        self.__parser_arrays()\n\n    def _get_maxlen(self):\n        return max([len(x) for x in self.sentences]) + 1\n\n    def __build_sentences(self):\n\n        return [x for x in self.__df.groupby('Sentence').apply(\n            lambda xdef: [x for x in zip(\n                xdef.Word.values,\n                xdef.Tag.values\n            )]\n        )]\n\n    def __build_Xy(self):\n\n        self.__X = [[word for word, __ in value] for value in self.sentences]\n        self.__y = [[tag for __, tag in value] for value in self.sentences]\n\n    def __build_parsers(self):\n\n        self.word2idx = {value: idx + 2 for idx,\n                         value in enumerate(self.all_words)}\n        self.word2idx[\"UNK\"] = 1  \n        self.word2idx[\"PAD\"] = 0  \n\n        # Converte um index em Word\n        self.idx2word = {idx: value for value, idx in self.word2idx.items()}\n\n        # Converte Tag em ìndice\n        self.tag2idx = {value: idx + 1 for idx,\n                        value in enumerate(self.all_tags)}\n        self.tag2idx[\"PAD\"] = 0  \n\n        self.idx2tag = {idx: value for value, idx in self.tag2idx.items()}\n\n    def parser2categorical(self, y_pred, y_true):\n\n        pred_tag = [[self.idx2tag[idx] for idx in row] for row in y_pred]\n        y_true_tag = [[self.idx2tag[idx] for idx in row] for row in y_true]\n\n        return pred_tag, y_true_tag\n\n    def __parser_arrays(self):\n\n        tmp_X = [[self.word2idx[index] for index in value]\n                 for value in self.__X]\n        tmp_y = [[self.tag2idx[index] for index in value]\n                 for value in self.__y]\n\n        self.X_array = pad_sequences(maxlen=self.max_len,\n                                     sequences=tmp_X,\n                                     padding=\"post\",\n                                     value=0)\n\n        y_pad = pad_sequences(maxlen=self.max_len,\n                              sequences=tmp_y,\n                              padding=\"post\",\n                              value=0)\n\n        self.y_array_normal = y_pad\n        self.y_array = np.array(\n            [to_categorical(index, num_classes=self.num_tags, dtype='int8') for index in y_pad])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:11:24.617386Z","iopub.execute_input":"2023-05-25T09:11:24.617821Z","iopub.status.idle":"2023-05-25T09:11:24.639726Z","shell.execute_reply.started":"2023-05-25T09:11:24.617788Z","shell.execute_reply":"2023-05-25T09:11:24.638644Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def build_matrix_embeddings(path, num_tokens, embedding_dim, word_index):\n    \"\"\"\n        Function to load pre-trained files into memory\n        \n    \"\"\"\n\n    hits, misses = 0, 0\n    embeddings_index = {}\n\n    print('Loading file...')\n\n    sleep(0.5)\n\n    for line in tqdm(open(path, encoding='utf-8')):\n        word, coefs = line.split(maxsplit=1)\n        embeddings_index[word] = np.fromstring(coefs, \"f\", sep=\" \")\n\n    print(\"Found %s Word Vectors.\" % len(embeddings_index))\n\n    sleep(0.5)\n\n    # Prepare embedding matrix\n    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n\n    for word, i in tqdm(word_index.items()):\n        if i >= num_tokens:\n            continue\n        try:\n            embedding_vector = embeddings_index.get(word)\n            if embedding_vector is not None:\n                embedding_matrix[i] = embedding_vector\n                hits += 1\n            else:\n                embedding_vector = embeddings_index.get(str(word).lower())\n                if embedding_vector is not None:\n                    embedding_matrix[i] = embedding_vector\n                    hits += 1\n                else:\n                    embedding_vector = embeddings_index.get(str(word).upper())\n                    if embedding_vector is not None:\n                        embedding_matrix[i] = embedding_vector\n                        hits += 1\n                misses += 1\n        except:\n            embedding_matrix[i] = embeddings_index.get('UNK')\n\n    print(\"Converted: %d Tokens | Lost: %d Tokens\" % (hits, misses))\n\n    return embedding_matrix\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:11:40.220125Z","iopub.execute_input":"2023-05-25T09:11:40.220518Z","iopub.status.idle":"2023-05-25T09:11:40.233321Z","shell.execute_reply.started":"2023-05-25T09:11:40.220487Z","shell.execute_reply":"2023-05-25T09:11:40.232009Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ner_aux = ContextNER(df, df.Word.to_list())","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:11:48.530426Z","iopub.execute_input":"2023-05-25T09:11:48.530902Z","iopub.status.idle":"2023-05-25T09:11:49.977535Z","shell.execute_reply.started":"2023-05-25T09:11:48.530859Z","shell.execute_reply":"2023-05-25T09:11:49.976337Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n## <p style=\"background-color:#344ceb;font-family:Serif;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\"> Loading the pretrained Embedding</p>\n#### ","metadata":{}},{"cell_type":"code","source":"%%time\nfile_path = '/kaggle/input/glove6b100dtxt/glove.6B.100d.txt'\n\nglove_embeddings = \\\nbuild_matrix_embeddings(path=file_path,\n                        num_tokens=ner_aux.num_words, \n                        embedding_dim=100,\n                        word_index=ner_aux.word2idx)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:34:19.493160Z","iopub.execute_input":"2023-05-25T09:34:19.493557Z","iopub.status.idle":"2023-05-25T09:34:34.928249Z","shell.execute_reply.started":"2023-05-25T09:34:19.493523Z","shell.execute_reply":"2023-05-25T09:34:34.927258Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Loading file...\n","output_type":"stream"},{"name":"stderr","text":"400000it [00:14, 28281.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Found 400000 Word Vectors.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68355/68355 [00:00<00:00, 410049.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Converted: 9102 Tokens | Lost: 62991 Tokens\nCPU times: user 13.3 s, sys: 517 ms, total: 13.8 s\nWall time: 15.4 s\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_TRAIN, X_TEST, Y_TRAIN, Y_TEST  = train_test_split(ner_aux.X_array,ner_aux.y_array,test_size=0.3, random_state=42)\nX_TEST, X_VAL, Y_TEST, Y_VAL = train_test_split(X_TEST, Y_TEST, test_size=1/3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:31.526720Z","iopub.execute_input":"2023-05-25T09:41:31.527133Z","iopub.status.idle":"2023-05-25T09:41:32.297419Z","shell.execute_reply.started":"2023-05-25T09:41:31.527099Z","shell.execute_reply":"2023-05-25T09:41:32.296404Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(np.shape(X_TRAIN))\nprint(np.shape(X_TEST))\nprint(np.shape(X_VAL))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:32.299327Z","iopub.execute_input":"2023-05-25T09:41:32.299762Z","iopub.status.idle":"2023-05-25T09:41:32.306157Z","shell.execute_reply.started":"2023-05-25T09:41:32.299728Z","shell.execute_reply":"2023-05-25T09:41:32.305011Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(1539, 704)\n(440, 704)\n(220, 704)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_TRAIN = np.asarray(X_TRAIN).astype(np.float32)\nX_TEST = np.asarray(X_TEST).astype(np.float32)\nX_VAL = np.asarray(X_VAL).astype(np.float32)\n\nY_TRAIN = np.asarray(Y_TRAIN).astype(np.float32)\nY_TEST = np.asarray(Y_TEST).astype(np.float32)\nY_VAL = np.asarray(Y_VAL).astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:33.465125Z","iopub.execute_input":"2023-05-25T09:41:33.465677Z","iopub.status.idle":"2023-05-25T09:41:33.512935Z","shell.execute_reply.started":"2023-05-25T09:41:33.465642Z","shell.execute_reply":"2023-05-25T09:41:33.511929Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n## <p style=\"background-color:#344ceb;font-family:Serif;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\"> Char Embeddings</p>\n#### ","metadata":{"execution":{"iopub.status.busy":"2023-05-04T08:10:39.511639Z","iopub.execute_input":"2023-05-04T08:10:39.511987Z","iopub.status.idle":"2023-05-04T08:10:39.519586Z","shell.execute_reply.started":"2023-05-04T08:10:39.51196Z","shell.execute_reply":"2023-05-04T08:10:39.518205Z"}}},{"cell_type":"code","source":"#Chars Embeddings/features\ndef get_X_char(sentences, max_len,  max_len_char, char2idx):\n    X_char = []\n    for sentence in tqdm(sentences):\n        sent_seq = []\n        for i in range(max_len):\n            word_seq = []\n            for j in range(max_len_char):\n                try:\n                    word_seq.append(char2idx.get(sentence[i][0][j]))\n                except:\n                    word_seq.append(char2idx.get(\"PAD\"))\n            sent_seq.append(word_seq)\n        X_char.append(np.array(sent_seq))\n\n    return np.asarray(X_char)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:37.849534Z","iopub.execute_input":"2023-05-25T09:41:37.849913Z","iopub.status.idle":"2023-05-25T09:41:37.857803Z","shell.execute_reply.started":"2023-05-25T09:41:37.849882Z","shell.execute_reply":"2023-05-25T09:41:37.856679Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def save_best_model(path_folder, file_name, metric):\n\n    if metric == 'f1':\n        mode = 'max'\n        \n    elif metric == 'val_loss':\n        mode = 'min'\n        \n    return ModelCheckpoint(path_folder + file_name + '.h5',\n                           monitor=metric,\n                           mode=mode,\n                           verbose=1,\n                           save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:37.943656Z","iopub.execute_input":"2023-05-25T09:41:37.944228Z","iopub.status.idle":"2023-05-25T09:41:37.949778Z","shell.execute_reply.started":"2023-05-25T09:41:37.944190Z","shell.execute_reply":"2023-05-25T09:41:37.948815Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def show_true_pred(index, true_tag, pred_tag, idx2word, ner_source):\n\n    word_parser_idx = idx2word\n    TEST = ner_source[index]\n\n    print(\"{:25}   {:10}   {}\".format(\"Word\", \"True\", \"Pred\"))\n    print(\"=\" * 50)\n\n    for word, true, pred in zip([word_parser_idx[x] for x in TEST],\n                                 true_tag[index],\n                                 pred_tag[index]):\n        if pred != 'PAD':\n            print(\"{:25}   {:10}    {}\".format(word, true, pred))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:43.470026Z","iopub.execute_input":"2023-05-25T09:41:43.470386Z","iopub.status.idle":"2023-05-25T09:41:43.477990Z","shell.execute_reply.started":"2023-05-25T09:41:43.470358Z","shell.execute_reply":"2023-05-25T09:41:43.477016Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"chars = set([w_i for w in ner_aux.all_words for w_i in str(w)])\nn_chars = len(chars) + 2\nmax_len_char = 10","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:43.579428Z","iopub.execute_input":"2023-05-25T09:41:43.580088Z","iopub.status.idle":"2023-05-25T09:41:43.637496Z","shell.execute_reply.started":"2023-05-25T09:41:43.580053Z","shell.execute_reply":"2023-05-25T09:41:43.636625Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"char2idx = {c: i + 2 for i, c in enumerate(chars)}\nchar2idx[\"UNK\"] = 1\nchar2idx[\"PAD\"] = 0\nidx2char = {i: c for c, i in char2idx.items()}","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:45.083728Z","iopub.execute_input":"2023-05-25T09:41:45.084833Z","iopub.status.idle":"2023-05-25T09:41:45.090365Z","shell.execute_reply.started":"2023-05-25T09:41:45.084793Z","shell.execute_reply":"2023-05-25T09:41:45.089519Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X_train_char_X = [[ner_aux.idx2word[x] for x in sent] for sent in X_TRAIN]\nX_test_char_X = [[ner_aux.idx2word[x] for x in sent] for sent in X_TEST]\nX_val_char_X = [[ner_aux.idx2word[x] for x in sent] for sent in X_VAL]","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:41:45.300261Z","iopub.execute_input":"2023-05-25T09:41:45.300869Z","iopub.status.idle":"2023-05-25T09:41:51.233057Z","shell.execute_reply.started":"2023-05-25T09:41:45.300838Z","shell.execute_reply":"2023-05-25T09:41:51.231954Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_TRAIN_CHAR = get_X_char(X_train_char_X, ner_aux.max_len, max_len_char, char2idx)\nX_TEST_CHAR = get_X_char(X_test_char_X, ner_aux.max_len, max_len_char, char2idx)\nX_VAL_CHAR = get_X_char(X_val_char_X, ner_aux.max_len, max_len_char, char2idx)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:42:13.478007Z","iopub.execute_input":"2023-05-25T09:42:13.478375Z","iopub.status.idle":"2023-05-25T09:42:28.487389Z","shell.execute_reply.started":"2023-05-25T09:42:13.478345Z","shell.execute_reply":"2023-05-25T09:42:28.486436Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"100%|██████████| 1539/1539 [00:10<00:00, 145.26it/s]\n100%|██████████| 440/440 [00:02<00:00, 151.07it/s]\n100%|██████████| 220/220 [00:01<00:00, 152.07it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **<span style=\"color:#344ceb;\"> NER MODELING</span>**","metadata":{}},{"cell_type":"code","source":"def BiLSTM_CNN(isa_crf=True,words_weights=None,pre_trained=False,max_len=None,max_len_char=None,\n               num_words=None,num_tags=None,n_chars=None,kernel_size=None,filter_size=None,\n               hiden_layer=128,is_trainable=False,l2_reg=1e-6,learning_rate=0.001,dropout=0.2):\n\n    # Char Embbedings\n    chars_input = Input(shape=(max_len, max_len_char,), dtype='float32')\n    chars_embed = Embedding(input_dim=n_chars,\n                            output_dim=max_len_char,\n                            embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5))(chars_input)\n\n    chars_embed = TimeDistributed(Dropout(rate=dropout))(chars_embed)\n\n    # Cnn Features\n    chars_embed = TimeDistributed(Conv1D(kernel_size=kernel_size,\n                                         filters=filter_size,\n                                         padding='same',\n                                         activation='tanh',\n                                         strides=1))(chars_embed)\n\n    chars_embed = TimeDistributed(MaxPooling1D(\n        pool_size=max_len_char))(chars_embed)\n    chars_embed = TimeDistributed(Flatten())(chars_embed)\n\n    # Word Embbedings\n    words_input = Input(shape=(max_len,), dtype='float32')\n    words_embed = Embedding(input_dim=words_weights.shape[0],\n                            output_dim=words_weights.shape[1],\n                            weights=[words_weights],\n                            trainable=is_trainable)(words_input)\n\n    x = concatenate([words_embed, chars_embed])\n\n    BiLSTM = Bidirectional(LSTM(units=hiden_layer // 2,\n                                return_sequences=True,\n                                recurrent_dropout=0.1,\n                                kernel_regularizer=regularizers.l2(l2_reg)))(x)\n\n    BiLSTM = TimeDistributed(Dropout(rate=dropout))(BiLSTM)\n    BiLSTM = TimeDistributed(Dense(units=hiden_layer,\n                                   activation='relu'))(BiLSTM)\n\n#     crf = CRF(num_tags)\n#     decoded_sequence, potentials, sequence_length, chain_kernel = crf(BiLSTM)\n\n    BiLSTM = Dense(units=num_tags, activation='softmax')(BiLSTM)\n    \n    model = Model(inputs=[words_input, chars_input],\n                  outputs=BiLSTM)\n    \n    model.compile(optimizer=Adam(learning_rate=learning_rate),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n\n#     model.compile(optimizer=\"rmsprop\", loss='categorical_crossentropy',metrics=['accuracy'])\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:42:28.489414Z","iopub.execute_input":"2023-05-25T09:42:28.490027Z","iopub.status.idle":"2023-05-25T09:42:28.503942Z","shell.execute_reply.started":"2023-05-25T09:42:28.489989Z","shell.execute_reply":"2023-05-25T09:42:28.503339Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n## <p style=\"background-color:#344ceb;font-family:Serif;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\"> Setting Hyper Parameters</p>\n#### ","metadata":{}},{"cell_type":"code","source":"EPOCHS = 100\nDROPOUT = 0.2\nBATCH_SIZE = 64\nLEARNING_RATE = 0.01\nHIDEN_LAYER = 128\nL2_REG = 1e-9\nVALIDATION_SPLIT = 0.1\n\nFILTER_SIZE = 30\nKERNEL_SIZE = 3","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:50:41.251152Z","iopub.execute_input":"2023-05-25T09:50:41.251581Z","iopub.status.idle":"2023-05-25T09:50:41.258383Z","shell.execute_reply.started":"2023-05-25T09:50:41.251546Z","shell.execute_reply":"2023-05-25T09:50:41.256881Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = BiLSTM_CNN(isa_crf=True,\n                   words_weights=glove_embeddings,\n                   pre_trained=True,\n                   max_len=ner_aux.max_len,\n                   max_len_char=max_len_char,\n                   n_chars=n_chars,\n                   num_words=ner_aux.num_words,\n                   num_tags=ner_aux.num_tags,\n                   kernel_size=KERNEL_SIZE,\n                   filter_size=FILTER_SIZE,\n                   hiden_layer=HIDEN_LAYER,\n                   is_trainable=True,\n                   l2_reg=L2_REG,\n                   learning_rate=LEARNING_RATE,\n                   dropout=DROPOUT)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:50:44.747324Z","iopub.execute_input":"2023-05-25T09:50:44.747727Z","iopub.status.idle":"2023-05-25T09:50:45.473045Z","shell.execute_reply.started":"2023-05-25T09:50:44.747696Z","shell.execute_reply":"2023-05-25T09:50:45.472123Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n## <p style=\"background-color:#344ceb;font-family:Serif;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\"> Model Summary</p>","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n## <p style=\"background-color:#344ceb;font-family:Serif;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\"> Training the model</p>\n","metadata":{}},{"cell_type":"code","source":"# from keras.utils import plot_model\n# plot_model(model,to_file='model_bilstm_crf.png',\n#            show_shapes=True,\n#            show_layer_names=True,\n#            expand_nested=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"%%time\ncallbacks = keras.callbacks.EarlyStopping(monitor='categorical_crossentropy', patience=5,\n                         verbose=1, mode='max', restore_best_weights=True)\n\nX_TRAIN_CHAR = np.asarray(X_TRAIN_CHAR).astype(np.float32)\nX_VAL_CHAR = np.asarray(X_VAL_CHAR).astype(np.float32)\nX_TEST_CHAR = np.asarray(X_TEST_CHAR).astype(np.float32)\n\nHistory = \\\nmodel.fit([X_TRAIN, X_TRAIN_CHAR],\n           Y_TRAIN, \n           batch_size=BATCH_SIZE, \n           epochs=EPOCHS, \n           validation_data=([X_VAL, X_VAL_CHAR],Y_VAL),\n           callbacks=[callbacks])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T09:51:01.492922Z","iopub.execute_input":"2023-05-25T09:51:01.493639Z","iopub.status.idle":"2023-05-25T13:32:18.310437Z","shell.execute_reply.started":"2023-05-25T09:51:01.493603Z","shell.execute_reply":"2023-05-25T13:32:18.309332Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/100\n25/25 [==============================] - 141s 5s/step - loss: 0.3073 - accuracy: 0.9268 - val_loss: 0.1221 - val_accuracy: 0.9696\nEpoch 2/100\n25/25 [==============================] - 136s 5s/step - loss: 0.0960 - accuracy: 0.9737 - val_loss: 0.0840 - val_accuracy: 0.9763\nEpoch 3/100\n25/25 [==============================] - 136s 5s/step - loss: 0.0617 - accuracy: 0.9820 - val_loss: 0.0679 - val_accuracy: 0.9814\nEpoch 4/100\n25/25 [==============================] - 136s 5s/step - loss: 0.0426 - accuracy: 0.9874 - val_loss: 0.0612 - val_accuracy: 0.9824\nEpoch 5/100\n25/25 [==============================] - 137s 5s/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0615 - val_accuracy: 0.9827\nEpoch 6/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0656 - val_accuracy: 0.9820\nEpoch 7/100\n25/25 [==============================] - 136s 5s/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0669 - val_accuracy: 0.9827\nEpoch 8/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0756 - val_accuracy: 0.9833\nEpoch 9/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0759 - val_accuracy: 0.9828\nEpoch 10/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0839 - val_accuracy: 0.9833\nEpoch 11/100\n25/25 [==============================] - 135s 5s/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0829 - val_accuracy: 0.9825\nEpoch 12/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0881 - val_accuracy: 0.9811\nEpoch 13/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0861 - val_accuracy: 0.9826\nEpoch 14/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0953 - val_accuracy: 0.9830\nEpoch 15/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1033 - val_accuracy: 0.9832\nEpoch 16/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.1002 - val_accuracy: 0.9830\nEpoch 17/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1008 - val_accuracy: 0.9826\nEpoch 18/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1024 - val_accuracy: 0.9829\nEpoch 19/100\n25/25 [==============================] - 135s 5s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1020 - val_accuracy: 0.9825\nEpoch 20/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1039 - val_accuracy: 0.9826\nEpoch 21/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1132 - val_accuracy: 0.9831\nEpoch 22/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1077 - val_accuracy: 0.9827\nEpoch 23/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1180 - val_accuracy: 0.9831\nEpoch 24/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1177 - val_accuracy: 0.9831\nEpoch 25/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1179 - val_accuracy: 0.9826\nEpoch 26/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1206 - val_accuracy: 0.9831\nEpoch 27/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.1140 - val_accuracy: 0.9828\nEpoch 28/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1225 - val_accuracy: 0.9828\nEpoch 29/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1236 - val_accuracy: 0.9827\nEpoch 30/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.1180 - val_accuracy: 0.9828\nEpoch 31/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1191 - val_accuracy: 0.9827\nEpoch 32/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1236 - val_accuracy: 0.9827\nEpoch 33/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1271 - val_accuracy: 0.9829\nEpoch 34/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1224 - val_accuracy: 0.9830\nEpoch 35/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1236 - val_accuracy: 0.9826\nEpoch 36/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1292 - val_accuracy: 0.9829\nEpoch 37/100\n25/25 [==============================] - 135s 5s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1264 - val_accuracy: 0.9827\nEpoch 38/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1279 - val_accuracy: 0.9824\nEpoch 39/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1307 - val_accuracy: 0.9824\nEpoch 40/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1278 - val_accuracy: 0.9817\nEpoch 41/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1169 - val_accuracy: 0.9821\nEpoch 42/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1136 - val_accuracy: 0.9829\nEpoch 43/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.1217 - val_accuracy: 0.9826\nEpoch 44/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1220 - val_accuracy: 0.9829\nEpoch 45/100\n25/25 [==============================] - 138s 6s/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.1242 - val_accuracy: 0.9826\nEpoch 46/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1306 - val_accuracy: 0.9827\nEpoch 47/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.1258 - val_accuracy: 0.9825\nEpoch 48/100\n25/25 [==============================] - 134s 5s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1309 - val_accuracy: 0.9824\nEpoch 49/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.1354 - val_accuracy: 0.9828\nEpoch 50/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1328 - val_accuracy: 0.9825\nEpoch 51/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1338 - val_accuracy: 0.9827\nEpoch 52/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1379 - val_accuracy: 0.9823\nEpoch 53/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.1353 - val_accuracy: 0.9822\nEpoch 54/100\n25/25 [==============================] - 130s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1345 - val_accuracy: 0.9827\nEpoch 55/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1402 - val_accuracy: 0.9828\nEpoch 56/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1379 - val_accuracy: 0.9827\nEpoch 57/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1380 - val_accuracy: 0.9828\nEpoch 58/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1383 - val_accuracy: 0.9825\nEpoch 59/100\n25/25 [==============================] - 132s 5s/step - loss: 9.8194e-04 - accuracy: 0.9996 - val_loss: 0.1433 - val_accuracy: 0.9827\nEpoch 60/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1385 - val_accuracy: 0.9825\nEpoch 61/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1408 - val_accuracy: 0.9829\nEpoch 62/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1419 - val_accuracy: 0.9824\nEpoch 63/100\n25/25 [==============================] - 135s 5s/step - loss: 9.8432e-04 - accuracy: 0.9995 - val_loss: 0.1430 - val_accuracy: 0.9826\nEpoch 64/100\n25/25 [==============================] - 130s 5s/step - loss: 9.9155e-04 - accuracy: 0.9996 - val_loss: 0.1446 - val_accuracy: 0.9826\nEpoch 65/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.1373 - val_accuracy: 0.9825\nEpoch 66/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.1437 - val_accuracy: 0.9825\nEpoch 67/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1447 - val_accuracy: 0.9825\nEpoch 68/100\n25/25 [==============================] - 132s 5s/step - loss: 9.9262e-04 - accuracy: 0.9996 - val_loss: 0.1488 - val_accuracy: 0.9825\nEpoch 69/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1446 - val_accuracy: 0.9822\nEpoch 70/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.1442 - val_accuracy: 0.9826\nEpoch 71/100\n25/25 [==============================] - 132s 5s/step - loss: 9.1180e-04 - accuracy: 0.9996 - val_loss: 0.1431 - val_accuracy: 0.9821\nEpoch 72/100\n25/25 [==============================] - 131s 5s/step - loss: 8.6325e-04 - accuracy: 0.9996 - val_loss: 0.1496 - val_accuracy: 0.9825\nEpoch 73/100\n25/25 [==============================] - 131s 5s/step - loss: 8.8457e-04 - accuracy: 0.9996 - val_loss: 0.1561 - val_accuracy: 0.9825\nEpoch 74/100\n25/25 [==============================] - 132s 5s/step - loss: 9.4249e-04 - accuracy: 0.9996 - val_loss: 0.1462 - val_accuracy: 0.9825\nEpoch 75/100\n25/25 [==============================] - 132s 5s/step - loss: 8.6767e-04 - accuracy: 0.9996 - val_loss: 0.1550 - val_accuracy: 0.9826\nEpoch 76/100\n25/25 [==============================] - 133s 5s/step - loss: 9.0191e-04 - accuracy: 0.9996 - val_loss: 0.1497 - val_accuracy: 0.9823\nEpoch 77/100\n25/25 [==============================] - 132s 5s/step - loss: 8.6868e-04 - accuracy: 0.9996 - val_loss: 0.1463 - val_accuracy: 0.9823\nEpoch 78/100\n25/25 [==============================] - 132s 5s/step - loss: 8.1303e-04 - accuracy: 0.9996 - val_loss: 0.1508 - val_accuracy: 0.9826\nEpoch 79/100\n25/25 [==============================] - 132s 5s/step - loss: 7.9212e-04 - accuracy: 0.9996 - val_loss: 0.1539 - val_accuracy: 0.9825\nEpoch 80/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1625 - val_accuracy: 0.9823\nEpoch 81/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1466 - val_accuracy: 0.9826\nEpoch 82/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1449 - val_accuracy: 0.9822\nEpoch 83/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.1353 - val_accuracy: 0.9823\nEpoch 84/100\n25/25 [==============================] - 131s 5s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1300 - val_accuracy: 0.9829\nEpoch 85/100\n25/25 [==============================] - 130s 5s/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.1477 - val_accuracy: 0.9830\nEpoch 86/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.1414 - val_accuracy: 0.9827\nEpoch 87/100\n25/25 [==============================] - 133s 5s/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.1431 - val_accuracy: 0.9827\nEpoch 88/100\n25/25 [==============================] - 132s 5s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.1482 - val_accuracy: 0.9828\nEpoch 89/100\n25/25 [==============================] - 131s 5s/step - loss: 9.5373e-04 - accuracy: 0.9995 - val_loss: 0.1512 - val_accuracy: 0.9828\nEpoch 90/100\n25/25 [==============================] - 132s 5s/step - loss: 8.6204e-04 - accuracy: 0.9995 - val_loss: 0.1528 - val_accuracy: 0.9827\nEpoch 91/100\n25/25 [==============================] - 133s 5s/step - loss: 7.9284e-04 - accuracy: 0.9996 - val_loss: 0.1564 - val_accuracy: 0.9827\nEpoch 92/100\n25/25 [==============================] - 133s 5s/step - loss: 6.9823e-04 - accuracy: 0.9996 - val_loss: 0.1609 - val_accuracy: 0.9829\nEpoch 93/100\n25/25 [==============================] - 133s 5s/step - loss: 7.3382e-04 - accuracy: 0.9996 - val_loss: 0.1641 - val_accuracy: 0.9828\nEpoch 94/100\n25/25 [==============================] - 134s 5s/step - loss: 7.1979e-04 - accuracy: 0.9996 - val_loss: 0.1628 - val_accuracy: 0.9828\nEpoch 95/100\n25/25 [==============================] - 132s 5s/step - loss: 7.2436e-04 - accuracy: 0.9996 - val_loss: 0.1715 - val_accuracy: 0.9828\nEpoch 96/100\n25/25 [==============================] - 131s 5s/step - loss: 6.9907e-04 - accuracy: 0.9996 - val_loss: 0.1685 - val_accuracy: 0.9829\nEpoch 97/100\n25/25 [==============================] - 130s 5s/step - loss: 8.1693e-04 - accuracy: 0.9996 - val_loss: 0.1736 - val_accuracy: 0.9827\nEpoch 98/100\n25/25 [==============================] - 131s 5s/step - loss: 7.6563e-04 - accuracy: 0.9996 - val_loss: 0.1692 - val_accuracy: 0.9826\nEpoch 99/100\n25/25 [==============================] - 131s 5s/step - loss: 7.2812e-04 - accuracy: 0.9996 - val_loss: 0.1721 - val_accuracy: 0.9827\nEpoch 100/100\n25/25 [==============================] - 133s 5s/step - loss: 8.3739e-04 - accuracy: 0.9996 - val_loss: 0.1753 - val_accuracy: 0.9826\nCPU times: user 5h 17min 5s, sys: 38min 19s, total: 5h 55min 25s\nWall time: 3h 41min 16s\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom keras.callbacks import Callback\nfrom seqeval.metrics import f1_score\nfrom seqeval.metrics import recall_score\nfrom seqeval.metrics import accuracy_score\nfrom seqeval.metrics import precision_score\nfrom seqeval.metrics import classification_report\n\nclass F1Metrics(Callback):\n\n    def __init__(self, id2label, pad_value=0, validation_data=None, digits=4):\n\n        super(F1Metrics, self).__init__()\n        \n        self.id2label = id2label\n        self.pad_value = pad_value\n        self.validation_data = validation_data\n        self.digits = digits\n        self.is_fit = validation_data is None\n\n    def convert_idx_to_name(self, y, array_indexes):\n\n        y = [[self.id2label[idx] for idx in row[row_indexes]] for\n             row, row_indexes in zip(y, array_indexes)]\n        return y\n\n    def predict(self, X, y):\n\n        y_pred = self.model.predict_on_batch(X)\n\n        # reduce dimension.\n        y_true = np.argmax(y, -1)\n        y_pred = np.argmax(y_pred, -1)\n\n        non_pad_indexes = [np.nonzero(y_true_row != self.pad_value)[0] for y_true_row in y_true]\n\n        y_true = self.convert_idx_to_name(y_true, non_pad_indexes)\n        y_pred = self.convert_idx_to_name(y_pred, non_pad_indexes)\n\n        return y_true, y_pred\n\n    def score(self, y_true, y_pred):\n        \n        f_score = f1_score(y_true, y_pred)\n        r_score = recall_score(y_true, y_pred)\n        p_score = precision_score(y_true, y_pred)\n        \n        print('NER Metrics > precision_score: {:04.2f}  --  recall_score: {:04.2f}  --  f1_score: {:04.2f}'.format(p_score, r_score, f_score))\n        \n        return f_score, r_score, p_score\n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        if self.is_fit:\n            self.on_epoch_end_fit(epoch, logs)\n        else:\n            self.on_epoch_end_fit_generator(epoch, logs)\n\n    def on_epoch_end_fit(self, epoch, logs={}):\n        \n        X = self.validation_data[0]\n        y = self.validation_data[1]\n        y_true, y_pred = self.predict(X, y)\n\n        f_score,\\\n        r_score,\\\n        p_score = self.score(y_true, y_pred)\n        \n        logs['f1'], logs['recall'], logs['precision'] = f_score, r_score, p_score\n        \n\n    def on_epoch_end_fit_generator(self, epoch, logs={}):\n        \n        y_true = []\n        y_pred = []\n        \n        for X, y in self.validation_data:\n            y_true_batch, y_pred_batch = self.predict(X, y)\n            y_true.extend(y_true_batch)\n            y_pred.extend(y_pred_batch)\n\n        f_score,\\\n        r_score,\\\n        p_score = self.score(y_true, y_pred)\n        \n        logs['f1'], logs['recall'], logs['precision'] = f_score, r_score, p_score\n        \n        \n        \ndef all_metrics(pred_tag, true_tag):\n\n    print(classification_report(pred_tag, true_tag))\n    print('=' * 25)\n    print(\"Precision: \\t\", precision_score(pred_tag, true_tag))\n    print(\"Recall: \\t\", recall_score(pred_tag, true_tag))\n    print(\"F1: \\t\\t\", f1_score(pred_tag, true_tag))\n    \ndef all_metrics_fold(pred_tag, true_tag):\n\n    print('=' * 25)\n    print(\"Precision: \\t\", precision_score(pred_tag, true_tag))\n    print(\"Recall: \\t\", recall_score(pred_tag, true_tag))\n    print(\"F1: \\t\\t\", f1_score(pred_tag, true_tag))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T13:32:18.312599Z","iopub.execute_input":"2023-05-25T13:32:18.313156Z","iopub.status.idle":"2023-05-25T13:32:18.341912Z","shell.execute_reply.started":"2023-05-25T13:32:18.313118Z","shell.execute_reply":"2023-05-25T13:32:18.341094Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"9\"></a>\n## <p style=\"background-color:#344ceb;font-family:Serif;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\"> Evaluating the model</p>\n","metadata":{}},{"cell_type":"code","source":"X_TEST = np.asarray(X_TEST).astype(np.float32)\nX_TEST_CHAR = np.asarray(X_TEST_CHAR).astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T13:32:18.343111Z","iopub.execute_input":"2023-05-25T13:32:18.343471Z","iopub.status.idle":"2023-05-25T13:32:18.366352Z","shell.execute_reply.started":"2023-05-25T13:32:18.343437Z","shell.execute_reply":"2023-05-25T13:32:18.365381Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"del X_TRAIN, \ndel X_TRAIN_CHAR\ndel Y_TRAIN","metadata":{"execution":{"iopub.status.busy":"2023-05-25T13:32:18.368647Z","iopub.execute_input":"2023-05-25T13:32:18.368941Z","iopub.status.idle":"2023-05-25T13:32:18.377793Z","shell.execute_reply.started":"2023-05-25T13:32:18.368917Z","shell.execute_reply":"2023-05-25T13:32:18.376995Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"y_pred, y_true = \\\nnp.argmax(model.predict([X_TEST, X_TEST_CHAR], verbose=1, batch_size=64), axis=-1), \\\nnp.argmax(Y_TEST, -1)\n\npred_tag, true_tag = \\\nner_aux.parser2categorical(y_pred, y_true) \n\nall_metrics(pred_tag, true_tag)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T13:32:18.379443Z","iopub.execute_input":"2023-05-25T13:32:18.379744Z","iopub.status.idle":"2023-05-25T13:32:38.526737Z","shell.execute_reply.started":"2023-05-25T13:32:18.379717Z","shell.execute_reply":"2023-05-25T13:32:38.525431Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"7/7 [==============================] - 4s 480ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"                               precision    recall  f1-score   support\n\n                           AD       1.00      1.00      1.00       440\n                 Organization       0.24      0.16      0.19       372\n         Organization,B-Place       0.29      0.45      0.35        47\n        Organization,I-Person       0.00      0.00      0.00         0\nOrganization,I-Person,B-Place       0.00      0.00      0.00         0\nOrganization,I-Person,I-Place       0.00      0.00      0.00         0\n         Organization,I-Place       0.13      0.33      0.19        15\n                       Person       0.49      0.48      0.48      2401\n               Person,B-Place       0.46      0.60      0.52        30\n               Person,I-Place       0.15      0.33      0.21         6\n                        Place       0.40      0.40      0.40       865\n\n                    micro avg       0.50      0.49      0.50      4176\n                    macro avg       0.29      0.34      0.30      4176\n                 weighted avg       0.50      0.49      0.49      4176\n\n=========================\nPrecision: \t 0.5040811278753401\nRecall: \t 0.48802681992337166\nF1: \t\t 0.495924078355031\n","output_type":"stream"}]},{"cell_type":"code","source":"def show_true_pred(index, true_tag, pred_tag, idx2word, ner_source):\n\n    word_parser_idx = idx2word\n    TEST = ner_source[index]\n\n    print(\"{:25}   {:10}   {}\".format(\"Word\", \"True\", \"Pred\"))\n    print(\"=\" * 50)\n\n    for word, true, pred in zip([word_parser_idx[x] for x in TEST[:50]],\n                                 true_tag[index],\n                                 pred_tag[index]):\n        if pred != 'PAD':\n            print(\"{:25}   {:10}    {}\".format(word, true, pred))\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-25T13:32:38.528391Z","iopub.execute_input":"2023-05-25T13:32:38.529098Z","iopub.status.idle":"2023-05-25T13:32:38.536135Z","shell.execute_reply.started":"2023-05-25T13:32:38.529060Z","shell.execute_reply":"2023-05-25T13:32:38.534984Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"10\"></a>\n## <p style=\"background-color:#344ceb;font-family:Serif;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\"> Result Report</p>\n","metadata":{}},{"cell_type":"code","source":"for index in range(2):\n    show_true_pred(index, pred_tag, true_tag, ner_aux.idx2word, X_TEST)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T13:32:38.537721Z","iopub.execute_input":"2023-05-25T13:32:38.541620Z","iopub.status.idle":"2023-05-25T13:32:38.564442Z","shell.execute_reply.started":"2023-05-25T13:32:38.541593Z","shell.execute_reply":"2023-05-25T13:32:38.563309Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Word                        True         Pred\n==================================================\n.                           O             O\nendutie                     O             O\nGehouden                    O             O\nken                         O             O\nHoldij                      B-Place       B-Place\nL:                          O             O\nB:                          B-Person      O\nComptoir                    B-Place       B-Place\nonder                       O             O\ndato                        O             O\n13.'                        O             O\nfebruarij                   O             O\n1759.                       O             O\nn                           O             O\noverleden                   O             O\n1e                          O             O\nKretschmar                  B-Person      B-Person\nhan                         O             O\ne                           O             O\ngemeijnd                    O             O\nvolgt                       O             O\nDit                         O             O\nPrgul                       O             O\ndiens                       O             O\ntot                         O             O\nde                          O             O\n8                           O             O\n4                           O             O\n36—                         O             O\nnleggende                   O             O\nInventaris                  O             O\nvan                         O             O\n1.24.                       O             O\nDen                         O             O\nLuijtenant                  B-Person      O\nJohan                       B-Person      B-Person\n30                          O             O\n—                           O             O\nCarel                       B-Person      B-Person\nvan                         I-Person      I-Person\nIlten                       I-Person      I-Person\n2.12.—                      O             O\n1759                        O             O\nCarel                       B-Person      B-Person\nvan                         I-Person      I-Person\nIten                        I-Person      I-Person\n1.36                        O             O\n—                           O             O\n24                          O             O\n1.24-                       O             O\nWord                        True         Pred\n==================================================\nDeses                       O             O\nnevens                      O             O\nden                         O             O\ntestateuren                 O             O\nende                        O             O\nmij                         O             O\nd                           O             O\nbehoorlijk                  O             O\nonderteekend                O             O\n/:                          O             O\nonderstant/                 O             O\nquoo„                       O             O\nmacor:                      O             O\n/                           O             O\nwasgeteekend:/              O             O\nP:                          B-Person      B-Person\nRas                         I-Person      I-Person\n/onderstand                 O             O\naccordeert                  O             O\n/wasgeteekend/              O             O\nS:                          B-Person      B-Person\nA:                          I-Person      I-Person\nDrier                       I-Person      I-Person\nsiriba                      O             O\n/                           O             O\nnog                         O             O\nlager/                      O             O\nAccordeert                  O             O\n/                           O             O\nwas                         O             O\ngeteekend/                  O             O\nI:                          B-Person      B-Person\nDreier                      I-Person      I-Person\ngesm                        O             O\nfrriba                      O             O\nExtract                     O             O\nuijt                        O             O\nde                          O             O\naanteekening                O             O\nhouden                      O             O\nin                          O             O\nRaade                       O             O\nvan                         O             O\nIustitie                    O             O\nSamarang                    B-Place       B-Place\nop                          O             O\nDingsdag                    O             O\nden                         O             O\nJunij                       O             O\n1783.                       O             O\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}