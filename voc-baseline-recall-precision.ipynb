{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\nimport torch\nimport transformers\nfrom transformers import BertForTokenClassification, AdamW\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, BertConfig\n\nfrom keras.utils import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom transformers import get_linear_schedule_with_warmup\n\n!pip install seqeval\nfrom seqeval.metrics import f1_score, accuracy_score\nfrom tqdm import tqdm, trange\n\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nMAX_LEN = 75\nbs = 32\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\n\ntransformers.__version__\ntorch.__version__","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-06T20:22:45.538493Z","iopub.execute_input":"2023-05-06T20:22:45.539751Z","iopub.status.idle":"2023-05-06T20:23:22.530269Z","shell.execute_reply.started":"2023-05-06T20:22:45.539572Z","shell.execute_reply":"2023-05-06T20:23:22.528607Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.21.6)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.0.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=1a7f8e75f19b02612812141922dcb4e3704353cb9fabd580f1c018c5130110c6\n  Stored in directory: /root/.cache/pip/wheels/b2/a1/b7/0d3b008d0c77cd57332d724b92cf7650b4185b493dc785f00a\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'1.13.0+cpu'"},"metadata":{}}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/voc-processed-data/train-nl.tsv\", sep=\"\\t\")\nlen(train)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:22.532481Z","iopub.execute_input":"2023-05-06T20:23:22.532991Z","iopub.status.idle":"2023-05-06T20:23:22.978066Z","shell.execute_reply.started":"2023-05-06T20:23:22.532936Z","shell.execute_reply":"2023-05-06T20:23:22.976501Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"359695"},"metadata":{}}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:22.980888Z","iopub.execute_input":"2023-05-06T20:23:22.981319Z","iopub.status.idle":"2023-05-06T20:23:23.020280Z","shell.execute_reply.started":"2023-05-06T20:23:22.981277Z","shell.execute_reply":"2023-05-06T20:23:23.019112Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                               TOKEN NE-MAIN NE-PER-NAME  \\\n0                                                NaN     NaN         NaN   \n1                                    # language = nl     NaN         NaN   \n2  # document_path = ../data/annotated_data/A/NL-...     NaN         NaN   \n3                                              heste       O           O   \n4                                          afschrift       O           O   \n\n  NE-PER-GENDER NE-PER-LEGAL-STATUS NE-PER-ROLE NE-ORG-BENEFICIARY MISC  \n0           NaN                 NaN         NaN                NaN  NaN  \n1           NaN                 NaN         NaN                NaN  NaN  \n2           NaN                 NaN         NaN                NaN  NaN  \n3             O                   O           O                  O    _  \n4             O                   O           O                  O    _  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TOKEN</th>\n      <th>NE-MAIN</th>\n      <th>NE-PER-NAME</th>\n      <th>NE-PER-GENDER</th>\n      <th>NE-PER-LEGAL-STATUS</th>\n      <th>NE-PER-ROLE</th>\n      <th>NE-ORG-BENEFICIARY</th>\n      <th>MISC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td># language = nl</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td># document_path = ../data/annotated_data/A/NL-...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>heste</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>afschrift</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>_</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['NE-MAIN'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:23.022194Z","iopub.execute_input":"2023-05-06T20:23:23.022549Z","iopub.status.idle":"2023-05-06T20:23:23.057341Z","shell.execute_reply.started":"2023-05-06T20:23:23.022517Z","shell.execute_reply":"2023-05-06T20:23:23.055929Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"O                                  321262\nI-Person                            15444\nB-Person                             8216\nI-Place                              3766\nB-Place                              2856\nI-Organization                       2155\nB-Organization                        741\nI-Organization,B-Place                208\nI-Organization,I-Place                111\nI-Person,B-Place                      105\nI-Person,I-Place                       54\nB-Organization,I-Place                 25\nB-Person,I-Place                       19\nI-Organization,I-Person                 4\nB-Organization,B-Place                  2\nB-Person,B-Place                        2\nB-Organization,I-Person                 1\nI-Organization,I-Person,B-Place         1\nI-Organization,I-Person,I-Place         1\nName: NE-MAIN, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df = train\ndf['DOC PATH'] = df['TOKEN'].str.extract(r'# document_path = (.*)', expand=False).ffill()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:23.059031Z","iopub.execute_input":"2023-05-06T20:23:23.059417Z","iopub.status.idle":"2023-05-06T20:23:23.253275Z","shell.execute_reply.started":"2023-05-06T20:23:23.059383Z","shell.execute_reply":"2023-05-06T20:23:23.251967Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Move Sentence # to the front\nsentence_col = df.pop('DOC PATH')\ndf.insert(0, 'DOC PATH', sentence_col)\n\ndf = df.dropna()\nprint(df.isnull().sum())\n# df = df.dropna(subset=[\"NE-MAIN\"])\n# df = df.dropna(subset=[\"TOKEN\"])\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:23.254900Z","iopub.execute_input":"2023-05-06T20:23:23.255324Z","iopub.status.idle":"2023-05-06T20:23:23.761651Z","shell.execute_reply.started":"2023-05-06T20:23:23.255284Z","shell.execute_reply":"2023-05-06T20:23:23.760111Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"DOC PATH               0\nTOKEN                  0\nNE-MAIN                0\nNE-PER-NAME            0\nNE-PER-GENDER          0\nNE-PER-LEGAL-STATUS    0\nNE-PER-ROLE            0\nNE-ORG-BENEFICIARY     0\nMISC                   0\ndtype: int64\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                            DOC PATH      TOKEN NE-MAIN  \\\n3  ../data/annotated_data/A/NL-HaNA_1.04.02_6857_...      heste       O   \n4  ../data/annotated_data/A/NL-HaNA_1.04.02_6857_...  afschrift       O   \n5  ../data/annotated_data/A/NL-HaNA_1.04.02_6857_...          m       O   \n6  ../data/annotated_data/A/NL-HaNA_1.04.02_6857_...         In       O   \n7  ../data/annotated_data/A/NL-HaNA_1.04.02_6857_...        den       O   \n\n  NE-PER-NAME NE-PER-GENDER NE-PER-LEGAL-STATUS NE-PER-ROLE  \\\n3           O             O                   O           O   \n4           O             O                   O           O   \n5           O             O                   O           O   \n6           O             O                   O           O   \n7           O             O                   O           O   \n\n  NE-ORG-BENEFICIARY MISC  \n3                  O    _  \n4                  O    _  \n5                  O    _  \n6                  O    _  \n7                  O    _  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DOC PATH</th>\n      <th>TOKEN</th>\n      <th>NE-MAIN</th>\n      <th>NE-PER-NAME</th>\n      <th>NE-PER-GENDER</th>\n      <th>NE-PER-LEGAL-STATUS</th>\n      <th>NE-PER-ROLE</th>\n      <th>NE-ORG-BENEFICIARY</th>\n      <th>MISC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>../data/annotated_data/A/NL-HaNA_1.04.02_6857_...</td>\n      <td>heste</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../data/annotated_data/A/NL-HaNA_1.04.02_6857_...</td>\n      <td>afschrift</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>../data/annotated_data/A/NL-HaNA_1.04.02_6857_...</td>\n      <td>m</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>../data/annotated_data/A/NL-HaNA_1.04.02_6857_...</td>\n      <td>In</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>_</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>../data/annotated_data/A/NL-HaNA_1.04.02_6857_...</td>\n      <td>den</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>_</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df[(df != 'O').all(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[(df.iloc[:, :-3] != 'O').all(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class SentenceGetter(object):\n# # https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/\n#     def __init__(self, df):\n#         self.n_sent = 1\n#         self.df = df\n#         self.empty = False\n#         agg_func = lambda s: [(t,a,n,g,l,r,b,m) for t,a,n,g,l,r,b,m in zip(s[\"TOKEN\"].values.tolist(),\n#                                                     s[\"NE-MAIN\"].values.tolist(),\n#                                                     s[\"NE-PER-NAME\"].values.tolist(),\n#                                                     s[\"NE-PER-GENDER\"].values.tolist(),\n#                                                     s[\"NE-PER-LEGAL-STATUS\"].values.tolist(),\n#                                                     s[\"NE-PER-ROLE\"].values.tolist(),\n#                                                     s[\"NE-ORG-BENEFICIARY\"].values.tolist(),\n#                                                     s[\"MISC\"].values.tolist())]\n#         self.grouped = self.df.groupby(\"DOC PATH\").apply(agg_func)\n#         self.sentences = [s for s in self.grouped]\n\n#     def get_next(self):\n#         try:\n#             s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n#             self.n_sent += 1\n#             return s\n#         except:\n#             return None\n\n\nclass SentenceGetter(object):\n\n    def __init__(self, data):\n        self.n_sent = 1\n        self.data = data\n        self.empty = False\n        agg_func = lambda s: [(w, t) for w, t in zip(s[\"TOKEN\"].values.tolist(),\n                                                           s[\"NE-MAIN\"].values.tolist())]\n        self.grouped = self.data.groupby(\"DOC PATH\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n\n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:23.763344Z","iopub.execute_input":"2023-05-06T20:23:23.764287Z","iopub.status.idle":"2023-05-06T20:23:23.774179Z","shell.execute_reply.started":"2023-05-06T20:23:23.764225Z","shell.execute_reply":"2023-05-06T20:23:23.772478Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"getter = SentenceGetter(df)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:23.778943Z","iopub.execute_input":"2023-05-06T20:23:23.779397Z","iopub.status.idle":"2023-05-06T20:23:24.213234Z","shell.execute_reply.started":"2023-05-06T20:23:23.779358Z","shell.execute_reply":"2023-05-06T20:23:24.212101Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\nsentences[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:24.214647Z","iopub.execute_input":"2023-05-06T20:23:24.214996Z","iopub.status.idle":"2023-05-06T20:23:24.268123Z","shell.execute_reply.started":"2023-05-06T20:23:24.214964Z","shell.execute_reply":"2023-05-06T20:23:24.266653Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['11',\n '„',\n '„',\n '35',\n 'in',\n 'beneven',\n 'zijn',\n 'Gemelde',\n 'aanbehumde',\n 'vader',\n 'de',\n 'voorneemde',\n '_',\n '5',\n 'tames',\n 'va',\n 'e2',\n '25',\n '6',\n 'welken',\n 'hy',\n 'testateur',\n 'betuigde',\n 'in',\n 'dienst',\n 'aangenemen',\n 'en',\n 'uitgevaren',\n 'te',\n 'zyn',\n 'ten',\n 'Eynde',\n 'door',\n 'haar',\n 'hoog',\n 'Edele',\n 'groot',\n 'agtb=r',\n 'uytgekeerd',\n 'te',\n 'werden',\n 'aan',\n 'de',\n 'geene',\n 'da',\n 'tot',\n 'dies',\n 'ontfangst',\n 'zal',\n 'ef',\n 'zullen',\n 'Wesen',\n 'gequalificeerd',\n 'Behuygende',\n 'den',\n 'toetateur',\n 'op',\n 'myne',\n 'gedane',\n 'verage',\n 'dat',\n 'zyn',\n 'beidel',\n 'beneden',\n 'de',\n 'Twee',\n 'duivend',\n 'rd:s',\n 'was',\n 'bedragen',\n 'de',\n 'voorts',\n 'heb',\n 'ik',\n 'Not:s',\n 'den',\n 'Poetaleur',\n 'behoorlyk',\n \"g'informeerd\",\n 'van',\n 'de',\n 'Jongste',\n 'besluyten',\n 'door',\n 'welmelde',\n 'hunne',\n 'hoog',\n 'Edelhedens',\n 'ten',\n 'op„',\n 'Bigt',\n 'van',\n 'de',\n 'Lijsteygenen',\n 'die',\n 'gedoopt',\n 'in',\n 'de',\n 'christelyke',\n 'leere',\n 'onderwesen',\n 'zijn',\n 'Successive',\n 'genamen.',\n 'Al',\n 'T',\n 'Gunt',\n 'voorsz:',\n 'staat',\n 'den',\n 'testateur',\n 'ure',\n 'en',\n 'duydelyk',\n 'voorge„',\n 'lesen',\n 'en',\n 'voorgehouden',\n 'in',\n 'by',\n 'zin',\n 'E:',\n 'zoo',\n 'hy',\n 'betuigde',\n 'wel',\n 'verstaan',\n 'zynde',\n 'begeerde',\n 'hy',\n 'dat',\n 'dat',\n 'instrument',\n 'zijn',\n 'volkomen',\n 'efect',\n 'mogte',\n 'ge„',\n 'pielen',\n 't',\n 'By',\n 'als',\n 'testaaren',\n 'Codicell',\n 'gifte',\n 'ter',\n 'zake',\n 'des',\n 'doods',\n 'chte',\n 'Eenige',\n 'andere',\n 'makinge',\n 'van',\n 'uytferste',\n 'Wille',\n 'zulx',\n '’t',\n 'zelve',\n 'best',\n 'na',\n 'regten',\n 'zal',\n 'konnen',\n 'bestaan,',\n 'schoon',\n 'de',\n 'nodige',\n 'Solemnityten',\n 'in',\n 'desen',\n 'gerequireerd',\n 'met',\n 'volkomen',\n 'waaren',\n \"G'observeerd:—\",\n 'Aldus',\n 'gedaan',\n 'ende',\n 'getesteerd',\n 'ten',\n 'huyse',\n 'Alss',\n 'in',\n 'den',\n 'hoofde',\n 'deses',\n 'gemeld',\n 'ter',\n 'presentie',\n 'van',\n 'Lucas',\n 'Andries',\n 'en',\n 'Carolustus',\n 'Johannesz',\n 'Clenq',\n 'als',\n 'geluygen',\n 'De',\n 'Minute',\n 'deses',\n 'is',\n 'behoorlyk',\n 'getek:d',\n 'en',\n 'gesz',\n 'op',\n 'Een',\n 'zegel',\n 'van',\n 'Een',\n 'Rd:s',\n '/onderstond/',\n 'quod',\n 'Altestor',\n '/',\n 'was',\n 'gesek:d',\n 'J:',\n 'N:',\n 'Bestbier',\n 'not:s',\n '/',\n 'ter',\n 'zyde',\n 'stond/',\n 'dit',\n 'testament',\n 'in',\n 'alhier',\n 'ter',\n 'Weest',\n 'gelesen',\n 'en',\n 'geregistreerd',\n 'ingevolge',\n 'heeren',\n 'weesen.',\n 'resolutie',\n 'van',\n 'Eato',\n 'deses',\n 'Batavia',\n 'in',\n 'de',\n 'wirsk:',\n 'den',\n '15:',\n 'xber',\n '1784:',\n '/was',\n 'Getekt/',\n 'H:',\n 'N:',\n 'Lacle',\n 'Secretaris.',\n '1',\n 'Ip',\n 'Huijden',\n 'den',\n '25:',\n 'November',\n '1784:',\n 'Des',\n 'nademiddags',\n 'te',\n 'halff',\n 'ses',\n 'uuren',\n 'Compareerde',\n 'voor',\n 'mij',\n 'Nicolaas',\n 'van',\n 'Bergen',\n 'van',\n 'der',\n 'Grijp',\n 'Not:o',\n 'publ:',\n 'bij',\n 'd’',\n 'Edele',\n 'hooge',\n 'regeringe',\n 'van',\n 'nederlands',\n 'indra',\n \"g'admitteerd\",\n 'binnen',\n 'de',\n 'stad',\n 'Batavia',\n 'resideerende',\n 'present',\n 'de',\n 'natemelden',\n 'getuijgen',\n 'den',\n '5:',\n 'Nicolaas',\n 'Iohannes',\n 'Ouman',\n 'adsistent',\n 'ten',\n 'dienste',\n 'der',\n 'E.',\n 'Comp:',\n 'woonende',\n 'af„',\n '„hier',\n 'my',\n 'bekend',\n 'zijnde',\n 'ziekelijk',\n 'van',\n 'Lichaam',\n 'dog',\n 'hebbende',\n 'zynde',\n 'volkomen']"},"metadata":{}}]},{"cell_type":"markdown","source":"The sentences are annotated with the BIO-schema and the labels look like this.","metadata":{}},{"cell_type":"code","source":"labels = [[s[1] for s in sentence] for sentence in getter.sentences]\nprint(labels[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:24.269741Z","iopub.execute_input":"2023-05-06T20:23:24.270204Z","iopub.status.idle":"2023-05-06T20:23:24.307561Z","shell.execute_reply.started":"2023-05-06T20:23:24.270162Z","shell.execute_reply":"2023-05-06T20:23:24.305613Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Person', 'I-Person', 'I-Person', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Person', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Place', 'I-Place', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Person', 'I-Person', 'O', 'B-Person', 'I-Person', 'I-Person', 'I-Person', 'I-Person', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Person', 'I-Person', 'I-Person', 'I-Person', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Place', 'I-Place', 'I-Place', 'I-Place', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Place', 'I-Place', 'I-Place', 'I-Place', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Person', 'I-Person', 'I-Person', 'I-Person', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Person', 'I-Person', 'I-Person', 'I-Person', 'I-Person', 'I-Person', 'I-Person', 'I-Person', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Place', 'I-Place', 'O', 'B-Place', 'I-Place', 'I-Place', 'I-Place', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Person', 'I-Person', 'I-Person', 'I-Person', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"}]},{"cell_type":"code","source":"tag_values = list(set(df[\"NE-MAIN\"].values))\n# tag_values = list(set(df[\"NE-MAIN\"].values) | set(df[\"NE-PER-NAME\"].values) | set(df[\"NE-PER-GENDER\"].values) | set(df[\"NE-PER-LEGAL-STATUS\"].values) | set(df[\"NE-PER-ROLE\"].values) | set(df[\"NE-ORG-BENEFICIARY\"].values) | set(df[\"MISC\"].values))\ntag_values.append(\"PAD\")\ntag2idx = {t: i for i, t in enumerate(tag_values)}","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:24.310442Z","iopub.execute_input":"2023-05-06T20:23:24.310913Z","iopub.status.idle":"2023-05-06T20:23:24.329471Z","shell.execute_reply.started":"2023-05-06T20:23:24.310871Z","shell.execute_reply":"2023-05-06T20:23:24.327718Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tag2idx","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:24.331628Z","iopub.execute_input":"2023-05-06T20:23:24.332141Z","iopub.status.idle":"2023-05-06T20:23:24.343999Z","shell.execute_reply.started":"2023-05-06T20:23:24.332089Z","shell.execute_reply":"2023-05-06T20:23:24.342166Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'I-Person,I-Place': 0,\n 'B-Organization,I-Place': 1,\n 'I-Place': 2,\n 'B-Organization,I-Person': 3,\n 'B-Person': 4,\n 'I-Person,B-Place': 5,\n 'B-Organization': 6,\n 'B-Place': 7,\n 'I-Organization,B-Place': 8,\n 'B-Person,I-Place': 9,\n 'B-Organization,B-Place': 10,\n 'I-Organization,I-Person': 11,\n 'B-Person,B-Place': 12,\n 'I-Organization,I-Person,I-Place': 13,\n 'I-Organization,I-Place': 14,\n 'I-Organization,I-Person,B-Place': 15,\n 'I-Organization': 16,\n 'O': 17,\n 'I-Person': 18,\n 'PAD': 19}"},"metadata":{}}]},{"cell_type":"code","source":"def get_tag_distribution(df, tag_col):\n    tag_distribution = df.groupby(tag_col).size().reset_index(name='counts')\n    tag_distribution = tag_distribution.sort_values('counts', ascending=False)\n    tag_distribution['percentage'] = (tag_distribution['counts'] / tag_distribution['counts'].sum()) * 100\n    return tag_distribution","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:24.345806Z","iopub.execute_input":"2023-05-06T20:23:24.346359Z","iopub.status.idle":"2023-05-06T20:23:24.358408Z","shell.execute_reply.started":"2023-05-06T20:23:24.346317Z","shell.execute_reply":"2023-05-06T20:23:24.356498Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"columns = ['NE-MAIN', 'NE-PER-NAME', 'NE-PER-GENDER', 'NE-PER-LEGAL-STATUS', 'NE-PER-ROLE', 'NE-ORG-BENEFICIARY', 'MISC']\nfor col in columns:\n    print(f\"Tag distribution for {col}:\")\n    print(get_tag_distribution(df, col))\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:24.360737Z","iopub.execute_input":"2023-05-06T20:23:24.361652Z","iopub.status.idle":"2023-05-06T20:23:24.602434Z","shell.execute_reply.started":"2023-05-06T20:23:24.361469Z","shell.execute_reply":"2023-05-06T20:23:24.600996Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Tag distribution for NE-MAIN:\n                            NE-MAIN  counts  percentage\n18                                O  321259   90.503141\n14                         I-Person   15444    4.350790\n4                          B-Person    8216    2.314562\n17                          I-Place    3766    1.060935\n7                           B-Place    2856    0.804575\n8                    I-Organization    2155    0.607094\n0                    B-Organization     741    0.208750\n9            I-Organization,B-Place     208    0.058597\n13           I-Organization,I-Place     111    0.031270\n15                 I-Person,B-Place     105    0.029580\n16                 I-Person,I-Place      54    0.015213\n3            B-Organization,I-Place      25    0.007043\n6                  B-Person,I-Place      19    0.005353\n10          I-Organization,I-Person       4    0.001127\n5                  B-Person,B-Place       2    0.000563\n1            B-Organization,B-Place       2    0.000563\n11  I-Organization,I-Person,B-Place       1    0.000282\n12  I-Organization,I-Person,I-Place       1    0.000282\n2           B-Organization,I-Person       1    0.000282\n\nTag distribution for NE-PER-NAME:\n    NE-PER-NAME  counts  percentage\n2             O  331588   93.412964\n1  I-ProperName   13026    3.669606\n0  B-ProperName   10356    2.917430\n\nTag distribution for NE-PER-GENDER:\n    NE-PER-GENDER  counts  percentage\n10              O  331123   93.281967\n6           I-Man    7443    2.096797\n8   I-Unspecified    6039    1.701271\n3   B-Unspecified    4075    1.147984\n1           B-Man    3115    0.877539\n9         I-Woman    1965    0.553568\n4         B-Woman     867    0.244246\n0         B-Group     276    0.077753\n5         I-Group      65    0.018311\n2   B-Man,I-Woman       1    0.000282\n7   I-Man,I-Woman       1    0.000282\n\nTag distribution for NE-PER-LEGAL-STATUS:\n  NE-PER-LEGAL-STATUS  counts  percentage\n6                   O  331123   93.281967\n5       I-Unspecified   14767    4.160070\n2       B-Unspecified    7581    2.135673\n0          B-Enslaved     568    0.160014\n3          I-Enslaved     533    0.150154\n4             I-Freed     303    0.085359\n1             B-Freed      95    0.026763\n\nTag distribution for NE-PER-ROLE:\n               NE-PER-ROLE  counts  percentage\n16                       O  331123   93.281967\n12                 I-Other    6519    1.836493\n3                  B-Other    4183    1.178409\n8            I-Beneficiary    2579    0.726540\n13              I-Testator    1951    0.549624\n15               I-Witness    1710    0.481731\n7          I-Acting_Notary    1322    0.372426\n1            B-Beneficiary    1275    0.359185\n11                I-Notary    1035    0.291574\n4               B-Testator     950    0.267628\n6                B-Witness     775    0.218328\n0          B-Acting_Notary     604    0.170155\n14  I-Testator_Beneficiary     423    0.119165\n2                 B-Notary     327    0.092120\n5   B-Testator_Beneficiary     192    0.054089\n9    I-Beneficiary,B-Other       1    0.000282\n10   I-Beneficiary,I-Other       1    0.000282\n\nTag distribution for NE-ORG-BENEFICIARY:\n  NE-ORG-BENEFICIARY  counts  percentage\n4                  O  351718   99.083866\n2               I-No    2066    0.582021\n0               B-No     648    0.182551\n3              I-Yes     416    0.117193\n1              B-Yes     122    0.034369\n\nTag distribution for MISC:\n                    MISC  counts  percentage\n0                      _  352338   99.258529\n42   partial-Person<0:5>     366    0.103107\n40   partial-Person<0:4>     319    0.089867\n44   partial-Person<0:6>     314    0.088458\n46   partial-Person<0:7>     281    0.079162\n..                   ...     ...         ...\n60   partial-Person<6:7>       1    0.000282\n61  partial-Person<8:10>       1    0.000282\n62  partial-Person<8:13>       1    0.000282\n63    partial-Place<0:0>       1    0.000282\n97    partial-Place<5:8>       1    0.000282\n\n[98 rows x 3 columns]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"classes = list(filter(lambda x: x not in [\"O\", np.nan], list(df[\"NE-MAIN\"].unique())))\nprint(classes)\n\n# tag_values = np.unique(df[['NE-MAIN', 'NE-PER-NAME', 'NE-PER-GENDER', 'NE-PER-LEGAL-STATUS', \n#                            'NE-PER-ROLE', 'NE-ORG-BENEFICIARY', 'MISC']].values)\n\n# # Filter out 'O' and nan values\n# classes = list(filter(lambda x: x not in [\"O\", np.nan], tag_values))\n# print(classes)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:24.604303Z","iopub.execute_input":"2023-05-06T20:23:24.605001Z","iopub.status.idle":"2023-05-06T20:23:24.637556Z","shell.execute_reply.started":"2023-05-06T20:23:24.604955Z","shell.execute_reply":"2023-05-06T20:23:24.636318Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['B-Person', 'I-Person', 'B-Place', 'I-Place', 'B-Organization', 'I-Organization', 'I-Person,B-Place', 'I-Person,I-Place', 'I-Organization,B-Place', 'I-Organization,I-Place', 'B-Organization,I-Place', 'B-Organization,I-Person', 'I-Organization,I-Person', 'I-Organization,I-Person,B-Place', 'I-Organization,I-Person,I-Place', 'B-Organization,B-Place', 'B-Person,I-Place', 'B-Person,B-Place']\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('GroNLP/bert-base-dutch-cased', do_lower_case=False) #bert-base-cased","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:24.639081Z","iopub.execute_input":"2023-05-06T20:23:24.639579Z","iopub.status.idle":"2023-05-06T20:23:27.577719Z","shell.execute_reply.started":"2023-05-06T20:23:24.639542Z","shell.execute_reply":"2023-05-06T20:23:27.576748Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"000ae38af8454ae4b67fb844a2f15511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6dc37a2cbd4a9493071df4f6beee90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/254 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56c099a5d1914ad0b313ddd344b6cc5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2bebdb845a14257aacca05b2677e015"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_and_preserve_labels(sentence, text_labels):\n    tokenized_sentence = []\n    labels = []\n\n    for word, label in zip(sentence, text_labels):\n\n        # Tokenize the word and count # of subwords the word is broken into\n        tokenized_word = tokenizer.tokenize(word)\n        n_subwords = len(tokenized_word)\n\n        # Add the tokenized word to the final tokenized word list\n        tokenized_sentence.extend(tokenized_word)\n\n        # Add the same label to the new list of labels `n_subwords` times\n        labels.extend([label] * n_subwords)\n\n    return tokenized_sentence, labels","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:27.579202Z","iopub.execute_input":"2023-05-06T20:23:27.579965Z","iopub.status.idle":"2023-05-06T20:23:27.587743Z","shell.execute_reply.started":"2023-05-06T20:23:27.579926Z","shell.execute_reply":"2023-05-06T20:23:27.586409Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenized_texts_and_labels = [\n    tokenize_and_preserve_labels(sent, labs)\n    for sent, labs in zip(sentences, labels)\n]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:27.589395Z","iopub.execute_input":"2023-05-06T20:23:27.589778Z","iopub.status.idle":"2023-05-06T20:23:48.230511Z","shell.execute_reply.started":"2023-05-06T20:23:27.589743Z","shell.execute_reply":"2023-05-06T20:23:48.229169Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\nlabels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:48.231907Z","iopub.execute_input":"2023-05-06T20:23:48.232302Z","iopub.status.idle":"2023-05-06T20:23:48.241538Z","shell.execute_reply.started":"2023-05-06T20:23:48.232267Z","shell.execute_reply":"2023-05-06T20:23:48.240124Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n                          truncating=\"post\", padding=\"post\")","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:48.243148Z","iopub.execute_input":"2023-05-06T20:23:48.243505Z","iopub.status.idle":"2023-05-06T20:23:49.115237Z","shell.execute_reply.started":"2023-05-06T20:23:48.243470Z","shell.execute_reply":"2023-05-06T20:23:49.113976Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n                     dtype=\"long\", truncating=\"post\")","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:49.116639Z","iopub.execute_input":"2023-05-06T20:23:49.117011Z","iopub.status.idle":"2023-05-06T20:23:49.246817Z","shell.execute_reply.started":"2023-05-06T20:23:49.116976Z","shell.execute_reply":"2023-05-06T20:23:49.245470Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"label_counts = np.unique(tags, return_counts=True)\nprint(label_counts) #number 13 occurs 334 times which is a lot (data is imbalanced)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:49.248465Z","iopub.execute_input":"2023-05-06T20:23:49.248828Z","iopub.status.idle":"2023-05-06T20:23:49.258132Z","shell.execute_reply.started":"2023-05-06T20:23:49.248794Z","shell.execute_reply":"2023-05-06T20:23:49.256625Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17,\n       18, 19]), array([    9,    14,  1667,     1,  3685,    88,   296,  1295,    88,\n           2,     7,     9,     1,    62,     2,   774, 98552,  7698,\n        3800]))\n","output_type":"stream"}]},{"cell_type":"code","source":"attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:49.264603Z","iopub.execute_input":"2023-05-06T20:23:49.265007Z","iopub.status.idle":"2023-05-06T20:23:49.505723Z","shell.execute_reply.started":"2023-05-06T20:23:49.264973Z","shell.execute_reply":"2023-05-06T20:23:49.504753Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n                                                            random_state=2018, test_size=0.1)\ntr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n                                             random_state=2018, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:49.507111Z","iopub.execute_input":"2023-05-06T20:23:49.507707Z","iopub.status.idle":"2023-05-06T20:23:49.518260Z","shell.execute_reply.started":"2023-05-06T20:23:49.507670Z","shell.execute_reply":"2023-05-06T20:23:49.516992Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tr_inputs = torch.tensor(tr_inputs)\nval_inputs = torch.tensor(val_inputs)\ntr_tags = torch.tensor(tr_tags)\nval_tags = torch.tensor(val_tags)\ntr_masks = torch.tensor(tr_masks)\nval_masks = torch.tensor(val_masks)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:49.520087Z","iopub.execute_input":"2023-05-06T20:23:49.520586Z","iopub.status.idle":"2023-05-06T20:23:49.570595Z","shell.execute_reply.started":"2023-05-06T20:23:49.520535Z","shell.execute_reply":"2023-05-06T20:23:49.569103Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n\nvalid_data = TensorDataset(val_inputs, val_masks, val_tags)\nvalid_sampler = SequentialSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:49.575177Z","iopub.execute_input":"2023-05-06T20:23:49.576740Z","iopub.status.idle":"2023-05-06T20:23:49.587474Z","shell.execute_reply.started":"2023-05-06T20:23:49.576692Z","shell.execute_reply":"2023-05-06T20:23:49.586149Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained(\n    \"GroNLP/bert-base-dutch-cased\",\n    num_labels=len(tag2idx),\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:23:49.589424Z","iopub.execute_input":"2023-05-06T20:23:49.590454Z","iopub.status.idle":"2023-05-06T20:24:06.124442Z","shell.execute_reply.started":"2023-05-06T20:23:49.590397Z","shell.execute_reply":"2023-05-06T20:24:06.122901Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/437M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51e77dce9b3c4f0ba03fd795bae8f6dd"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"FULL_FINETUNING = True\nif FULL_FINETUNING:\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.0}\n    ]\nelse:\n    param_optimizer = list(model.classifier.named_parameters())\n    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n\noptimizer = AdamW(\n    optimizer_grouped_parameters,\n    lr=3e-5,\n    eps=1e-8\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:24:06.126525Z","iopub.execute_input":"2023-05-06T20:24:06.127608Z","iopub.status.idle":"2023-05-06T20:24:06.164087Z","shell.execute_reply.started":"2023-05-06T20:24:06.127553Z","shell.execute_reply":"2023-05-06T20:24:06.162374Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 10\nmax_grad_norm = 1.0\n\n# Total number of training steps is number of batches * number of epochs.\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:24:06.166513Z","iopub.execute_input":"2023-05-06T20:24:06.167122Z","iopub.status.idle":"2023-05-06T20:24:06.175358Z","shell.execute_reply.started":"2023-05-06T20:24:06.167069Z","shell.execute_reply":"2023-05-06T20:24:06.173557Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"valid_seq_lens = []\nfor batch in valid_dataloader:\n    batch = tuple(t.to(device) for t in batch)\n    b_input_ids, b_input_mask, b_labels = batch\n    seq_lens = b_input_mask.sum(dim=1).tolist()\n    valid_seq_lens.extend(seq_lens)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:24:06.177735Z","iopub.execute_input":"2023-05-06T20:24:06.178300Z","iopub.status.idle":"2023-05-06T20:24:06.207432Z","shell.execute_reply.started":"2023-05-06T20:24:06.178246Z","shell.execute_reply":"2023-05-06T20:24:06.205940Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def nested_list(lst, seq_lens):\n    nested = []\n    i = 0\n    for seq_len in seq_lens:\n        nested.append(lst[i:i+seq_len])\n        i += seq_len\n    return nested","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:24:06.209645Z","iopub.execute_input":"2023-05-06T20:24:06.210143Z","iopub.status.idle":"2023-05-06T20:24:06.218030Z","shell.execute_reply.started":"2023-05-06T20:24:06.210092Z","shell.execute_reply":"2023-05-06T20:24:06.216316Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"valid_seq_lens = [int(x) for x in valid_seq_lens]\nvalid_seq_lens","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:24:06.220940Z","iopub.execute_input":"2023-05-06T20:24:06.221541Z","iopub.status.idle":"2023-05-06T20:24:06.240768Z","shell.execute_reply.started":"2023-05-06T20:24:06.221488Z","shell.execute_reply":"2023-05-06T20:24:06.239455Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[72,\n 71,\n 75,\n 72,\n 74,\n 73,\n 74,\n 74,\n 75,\n 74,\n 74,\n 72,\n 73,\n 75,\n 6,\n 75,\n 73,\n 74,\n 75,\n 73,\n 74,\n 72,\n 74,\n 74,\n 74,\n 73,\n 74,\n 75,\n 70,\n 75,\n 68,\n 75,\n 74,\n 72,\n 73,\n 7,\n 74,\n 74,\n 75,\n 75,\n 75,\n 68,\n 75,\n 75,\n 23,\n 68,\n 75,\n 73,\n 71,\n 71,\n 73,\n 73,\n 73,\n 71,\n 75,\n 75,\n 71,\n 75,\n 73,\n 74,\n 74,\n 73,\n 74,\n 75,\n 75,\n 73,\n 72,\n 75,\n 73,\n 74,\n 75,\n 73,\n 75,\n 74,\n 73,\n 74,\n 73,\n 75,\n 74,\n 75,\n 67,\n 72,\n 73,\n 74,\n 71,\n 73,\n 75,\n 75,\n 72,\n 70,\n 73,\n 75,\n 75,\n 72,\n 74,\n 61,\n 9,\n 72,\n 75,\n 73,\n 74,\n 73,\n 73,\n 54,\n 73,\n 73,\n 75,\n 73,\n 72,\n 74,\n 74,\n 73,\n 75,\n 75,\n 74,\n 73,\n 75,\n 64,\n 75,\n 73,\n 73,\n 75,\n 72,\n 74,\n 75,\n 74,\n 73,\n 75,\n 75,\n 72,\n 75,\n 75,\n 75,\n 73,\n 74,\n 75,\n 72,\n 66,\n 73,\n 74,\n 73,\n 75,\n 75,\n 73,\n 75,\n 73,\n 75,\n 74,\n 73,\n 73,\n 74,\n 73,\n 35,\n 75,\n 72,\n 74,\n 75,\n 75]"},"metadata":{}}]},{"cell_type":"code","source":"## Store the average loss after each epoch so we can plot them.\nloss_values, validation_loss_values = [], []\n\nprecision_values, validation_precision_values = [], []\nrecall_values, validation = recall_values = [],[]\n\n\nfor _ in trange(epochs, desc=\"Epoch\"):\n    # ========================================\n    #               Training\n    # ========================================\n    # Perform one full pass over the training set.\n\n    # Put the model into training mode.\n    model.train()\n    # Reset the total loss for this epoch.\n    total_loss = 0\n\n    # Training loop\n    for step, batch in enumerate(train_dataloader):\n        # add batch to gpu\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        # Always clear any previously calculated gradients before performing a backward pass.\n        model.zero_grad()\n        # forward pass\n        # This will return the loss (rather than the model output)\n        # because we have provided the `labels`.\n        outputs = model(b_input_ids, token_type_ids=None,\n                        attention_mask=b_input_mask, labels=b_labels)\n        # get the loss\n        loss = outputs[0]\n        # Perform a backward pass to calculate the gradients.\n        loss.backward()\n        # track train loss\n        total_loss += loss.item()\n        # Clip the norm of the gradient\n        # This is to help prevent the \"exploding gradients\" problem.\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n        # update parameters\n        optimizer.step()\n        # Update the learning rate.\n        scheduler.step()\n\n    # Calculate the average loss over the training data.\n    avg_train_loss = total_loss / len(train_dataloader)\n    print(\"Average train loss: {}\".format(avg_train_loss))\n\n    # Store the loss value for plotting the learning curve.\n    loss_values.append(avg_train_loss)\n\n\n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on\n    # our validation set.\n\n    # Put the model into evaluation mode\n    model.eval()\n    # Reset the validation loss for this epoch.\n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n    predictions , true_labels = [], []\n    for batch in valid_dataloader:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n\n        # Telling the model not to compute or store gradients,\n        # saving memory and speeding up validation\n        with torch.no_grad():\n            # Forward pass, calculate logit predictions.\n            # This will return the logits rather than the loss because we have not provided labels.\n            outputs = model(b_input_ids, token_type_ids=None,\n                            attention_mask=b_input_mask, labels=b_labels)\n        # Move logits and labels to CPU\n        logits = outputs[1].detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n        # Calculate the accuracy for this batch of test sentences.\n        eval_loss += outputs[0].mean().item()\n        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n        true_labels.extend(label_ids)\n\n    eval_loss = eval_loss / len(valid_dataloader)\n    validation_loss_values.append(eval_loss)\n    print(\"Validation loss: {}\".format(eval_loss))\n    for p, l in zip(predictions, true_labels):\n        for p_i, l_i in zip(p, l):\n            if tag_values[l_i] != \"PAD\" and l_i >= len(tag_values):\n                print(\"Problematic index:\", l_i)\n    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n    valid_tags = [tag_values[l_i] for l in true_labels\n                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n    \n    pred_tags_nested = nested_list(pred_tags,valid_seq_lens)\n    valid_tags_nested = nested_list(valid_tags,valid_seq_lens)\n    print(\"Validation F1-Score: {}\".format(f1_score(pred_tags_nested, valid_tags_nested)))\n    \n    precision = precision_score(pred_tags, valid_tags, average='weighted')\n    print('Validation Precision: %.3f' % precision)\n    \n    recall = recall_score(pred_tags, valid_tags, average='weighted')\n    print('Validation Recall: %.3f' % recall)\n    \n    print()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:24:06.242914Z","iopub.execute_input":"2023-05-06T20:24:06.243957Z","iopub.status.idle":"2023-05-06T20:32:38.669941Z","shell.execute_reply.started":"2023-05-06T20:24:06.243897Z","shell.execute_reply":"2023-05-06T20:32:38.668079Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Epoch:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Average train loss: 0.6792191233899858\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\nEpoch:   0%|          | 0/10 [08:31<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.4137593924999237\nValidation Accuracy: 0.8891298690032099\nValidation F1-Score: 0.19772727272727272\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_58/2001236752.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation F1-Score: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tags_nested\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tags_nested\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation Precision: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m     )\n\u001b[1;32m   1767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             raise ValueError(\n\u001b[1;32m   1366\u001b[0m                 \u001b[0;34m\"Target is %s but average='binary'. Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m                 \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m             )\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."],"ename":"ValueError","evalue":"Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].","output_type":"error"}]},{"cell_type":"code","source":"# Use plot styling from seaborn.\nsns.set(style='darkgrid')\n\n# Increase the plot size and font size.\nsns.set(font_scale=1.5)\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\n# Plot the learning curve.\nplt.plot(loss_values, 'b-o', label=\"training loss\")\nplt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n\n# Label the plot.\nplt.title(\"Learning curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_values, validation_loss_values = [], []\nprecision_values = []\nrecall_values = []\n\nfor _ in trange(epochs, desc=\"Epoch\"):\n    model.train()\n    total_loss = 0\n\n    for step, batch in enumerate(train_dataloader):\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        model.zero_grad()\n\n        outputs = model(b_input_ids, token_type_ids=None,\n                        attention_mask=b_input_mask, labels=b_labels)\n\n        loss = outputs[0]\n        loss.backward()\n        total_loss += loss.item()\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n        optimizer.step()\n        scheduler.step()\n\n    avg_train_loss = total_loss / len(train_dataloader)\n    print(\"Average train loss: {}\".format(avg_train_loss))\n    loss_values.append(avg_train_loss)\n    model.eval()\n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n    predictions , true_labels = [], []\n    for batch in valid_dataloader:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n\n        with torch.no_grad():\n            outputs = model(b_input_ids, token_type_ids=None,\n                            attention_mask=b_input_mask, labels=b_labels)\n        # Move logits and labels to CPU\n        logits = outputs[1].detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        eval_loss += outputs[0].mean().item()\n        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n        true_labels.extend(label_ids)\n\n    eval_loss = eval_loss / len(valid_dataloader)\n    validation_loss_values.append(eval_loss)\n    print(\"Validation loss: {}\".format(eval_loss))\n    for p, l in zip(predictions, true_labels):\n        for p_i, l_i in zip(p, l):\n            if tag_values[l_i] != \"PAD\" and l_i >= len(tag_values):\n                print(\"Problematic index:\", l_i)\n    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n    valid_tags = [tag_values[l_i] for l in true_labels\n                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n    \n    pred_tags_nested = nested_list(pred_tags,valid_seq_lens)\n    valid_tags_nested = nested_list(valid_tags,valid_seq_lens)\n    print(\"Validation F1-Score: {}\".format(f1_score(pred_tags_nested, valid_tags_nested)))\n    \n    precision = precision_score(pred_tags, valid_tags, average='weighted')\n    print('Validation Precision: %.3f' % precision)\n    precision_values.append(precision)\n    \n    recall = recall_score(pred_tags, valid_tags, average='weighted')\n    print('Validation Recall: %.3f' % recall)\n    recall_values.append(recall)\n    \n    print()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T21:01:56.571466Z","iopub.execute_input":"2023-05-06T21:01:56.571940Z","iopub.status.idle":"2023-05-06T22:26:32.026584Z","shell.execute_reply.started":"2023-05-06T21:01:56.571899Z","shell.execute_reply":"2023-05-06T22:26:32.025306Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Epoch:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Average train loss: 0.30151334040694766\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  10%|█         | 1/10 [08:31<1:16:46, 511.87s/it]","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.3027998089790344\nValidation Accuracy: 0.9174112952199185\nValidation F1-Score: 0.3186046511627907\nValidation Precision: 0.955\nValidation Recall: 0.917\n\nAverage train loss: 0.20899738056792153\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  20%|██        | 2/10 [16:56<1:07:38, 507.36s/it]","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.27134287655353545\nValidation Accuracy: 0.9263468378589399\nValidation F1-Score: 0.3815789473684211\nValidation Precision: 0.952\nValidation Recall: 0.926\n\nAverage train loss: 0.1560404971241951\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  30%|███       | 3/10 [25:22<59:08, 506.86s/it]  ","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.2738905489444733\nValidation Accuracy: 0.9267806020647176\nValidation F1-Score: 0.46640316205533594\nValidation Precision: 0.948\nValidation Recall: 0.927\n\nAverage train loss: 0.12493044353193707\nValidation loss: 0.258324059844017\nValidation Accuracy: 0.9280818946820508\nValidation F1-Score: 0.4730769230769231\nValidation Precision: 0.941\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  40%|████      | 4/10 [33:49<50:40, 506.80s/it]","output_type":"stream"},{"name":"stdout","text":"Validation Recall: 0.928\n\nAverage train loss: 0.09479276761412621\nValidation loss: 0.28281761705875397\nValidation Accuracy: 0.9249587924004511\nValidation F1-Score: 0.4820607175712972\nValidation Precision: 0.932\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  50%|█████     | 5/10 [42:16<42:15, 507.17s/it]","output_type":"stream"},{"name":"stdout","text":"Validation Recall: 0.925\n\nAverage train loss: 0.07885234985086653\nValidation loss: 0.30219981372356414\nValidation Accuracy: 0.924611781035829\nValidation F1-Score: 0.5036363636363637\nValidation Precision: 0.930\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  60%|██████    | 6/10 [50:46<33:51, 507.94s/it]","output_type":"stream"},{"name":"stdout","text":"Validation Recall: 0.925\n\nAverage train loss: 0.06878615725371573\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  70%|███████   | 7/10 [59:14<25:24, 508.02s/it]","output_type":"stream"},{"name":"stdout","text":"Validation loss: 0.30212242603302003\nValidation Accuracy: 0.9251322980827622\nValidation F1-Score: 0.5157799819657348\nValidation Precision: 0.929\nValidation Recall: 0.925\n\nAverage train loss: 0.059405335783958436\nValidation loss: 0.32264513373374937\nValidation Accuracy: 0.9273011191116509\nValidation F1-Score: 0.5122615803814715\nValidation Precision: 0.933\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  80%|████████  | 8/10 [1:07:43<16:56, 508.37s/it]","output_type":"stream"},{"name":"stdout","text":"Validation Recall: 0.927\n\nAverage train loss: 0.056028813123703\nValidation loss: 0.32635838985443116\nValidation Accuracy: 0.9270408605881842\nValidation F1-Score: 0.5064695009242144\nValidation Precision: 0.934\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch:  90%|█████████ | 9/10 [1:16:11<08:28, 508.24s/it]","output_type":"stream"},{"name":"stdout","text":"Validation Recall: 0.927\n\nAverage train loss: 0.05419353879988194\nValidation loss: 0.32635838985443116\nValidation Accuracy: 0.9270408605881842\nValidation F1-Score: 0.5064695009242144\nValidation Precision: 0.934\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch: 100%|██████████| 10/10 [1:24:35<00:00, 507.54s/it]","output_type":"stream"},{"name":"stdout","text":"Validation Recall: 0.927\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"precision_values","metadata":{"execution":{"iopub.status.busy":"2023-05-06T22:26:32.029163Z","iopub.execute_input":"2023-05-06T22:26:32.029535Z","iopub.status.idle":"2023-05-06T22:26:32.038232Z","shell.execute_reply.started":"2023-05-06T22:26:32.029499Z","shell.execute_reply":"2023-05-06T22:26:32.036850Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[0.9547716549246686,\n 0.9523524573558639,\n 0.9478315484478887,\n 0.9413670565221809,\n 0.9323452860977194,\n 0.929528427675173,\n 0.9291737633804815,\n 0.9334813052173022,\n 0.933871035295913,\n 0.933871035295913]"},"metadata":{}}]},{"cell_type":"code","source":"recall_values","metadata":{"execution":{"iopub.status.busy":"2023-05-06T22:26:32.040431Z","iopub.execute_input":"2023-05-06T22:26:32.040983Z","iopub.status.idle":"2023-05-06T22:26:32.051233Z","shell.execute_reply.started":"2023-05-06T22:26:32.040944Z","shell.execute_reply":"2023-05-06T22:26:32.049921Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[0.9174112952199185,\n 0.9263468378589399,\n 0.9267806020647176,\n 0.9280818946820508,\n 0.9249587924004511,\n 0.924611781035829,\n 0.9251322980827622,\n 0.9273011191116509,\n 0.9270408605881842,\n 0.9270408605881842]"},"metadata":{}}]},{"cell_type":"code","source":"from seqeval.metrics import classification_report\n\n# print(classification_report(labels, predictions))\n\n# obtain true and predicted labels\npred_tags_flat = [p_i for p in predictions for p_i in p]\nvalid_tags_flat = [l_i for l in true_labels for l_i in l]\n\n# generate classification report\ntarget_names = list(tag_values.values())[1:-1] # exclude \"PAD\" and \"O\" tags\nprint(classification_report(valid_tags_flat, pred_tags_flat, target_names=target_names))","metadata":{},"execution_count":null,"outputs":[]}]}